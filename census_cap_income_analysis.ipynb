{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (2017 Census Income Per Capita analysis)\n",
    "## by (Christopher James)\n",
    "\n",
    "## Preliminary Wrangling\n",
    "\n",
    "This dataset contains population, travel, work, and income information from the 2017 Census Bureau ACS survey. Wrangling was done in the notebook 'census_wrangle.ipynb' A summary of this can be found in the file 'wrangle_report.pdf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all packages and set plots to be embedded inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "\n",
    "# Set option to allow all rows and colums to be displayed in notebook.\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Any needed functions\n",
    "\n",
    "# returns mean absolute error for random forests.\n",
    "def get_mae(max_leaf_nodes, train_X, val_X, train_y, val_y):\n",
    "    model = RandomForestRegressor(max_leaf_nodes=max_leaf_nodes, random_state=1)\n",
    "    model.fit(train_X, train_y)\n",
    "    preds_val = model.predict(val_X)\n",
    "    mae = mean_absolute_error(val_y, preds_val)\n",
    "    return(mae)\n",
    "\n",
    "# Function to generate a random sample of df rows.\n",
    "def df_sample(dataframe, samp_size):\n",
    "    samples = np.random.choice(dataframe.shape[0], samp_size, replace = False)\n",
    "    return dataframe.loc[samples,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CSV file into dataframe\n",
    "df_original = pd.read_csv('acs2017_census_tract_data_master.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy dataframe before analysis begins.\n",
    "df = df_original.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 74001 entries, 0 to 74000\n",
      "Data columns (total 37 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   TractId           74001 non-null  int64  \n",
      " 1   State             74001 non-null  object \n",
      " 2   County            74001 non-null  object \n",
      " 3   TotalPop          74001 non-null  int64  \n",
      " 4   Men               74001 non-null  int64  \n",
      " 5   Women             74001 non-null  int64  \n",
      " 6   Hispanic          73305 non-null  float64\n",
      " 7   White             73305 non-null  float64\n",
      " 8   Black             73305 non-null  float64\n",
      " 9   Native            73305 non-null  float64\n",
      " 10  Asian             73305 non-null  float64\n",
      " 11  Pacific           73305 non-null  float64\n",
      " 12  VotingAgeCitizen  74001 non-null  int64  \n",
      " 13  Income            72885 non-null  float64\n",
      " 14  IncomeErr         72885 non-null  float64\n",
      " 15  IncomePerCap      73256 non-null  float64\n",
      " 16  IncomePerCapErr   73256 non-null  float64\n",
      " 17  Poverty           73159 non-null  float64\n",
      " 18  ChildPoverty      73024 non-null  float64\n",
      " 19  Professional      73190 non-null  float64\n",
      " 20  Service           73190 non-null  float64\n",
      " 21  Office            73190 non-null  float64\n",
      " 22  Construction      73190 non-null  float64\n",
      " 23  Production        73190 non-null  float64\n",
      " 24  Drive             73200 non-null  float64\n",
      " 25  Carpool           73200 non-null  float64\n",
      " 26  Transit           73200 non-null  float64\n",
      " 27  Walk              73200 non-null  float64\n",
      " 28  OtherTransp       73200 non-null  float64\n",
      " 29  WorkAtHome        73200 non-null  float64\n",
      " 30  MeanCommute       73055 non-null  float64\n",
      " 31  Employed          74001 non-null  int64  \n",
      " 32  PrivateWork       73190 non-null  float64\n",
      " 33  PublicWork        73190 non-null  float64\n",
      " 34  SelfEmployed      73190 non-null  float64\n",
      " 35  FamilyWork        73190 non-null  float64\n",
      " 36  Unemployment      73191 non-null  float64\n",
      "dtypes: float64(29), int64(6), object(2)\n",
      "memory usage: 20.9+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TractId            -0.063549\n",
       "TotalPop            0.040227\n",
       "Men                 0.030903\n",
       "Women               0.047965\n",
       "Hispanic           -0.304357\n",
       "White               0.373485\n",
       "Black              -0.283210\n",
       "Native             -0.076966\n",
       "Asian               0.216731\n",
       "Pacific            -0.024617\n",
       "VotingAgeCitizen    0.114150\n",
       "Income              0.836809\n",
       "IncomeErr           0.601452\n",
       "IncomePerCap        1.000000\n",
       "IncomePerCapErr     0.752062\n",
       "Poverty            -0.594810\n",
       "ChildPoverty       -0.571800\n",
       "Professional        0.800398\n",
       "Service            -0.580823\n",
       "Office             -0.134562\n",
       "Construction       -0.408269\n",
       "Production         -0.542442\n",
       "Drive              -0.046829\n",
       "Carpool            -0.347200\n",
       "Transit             0.077501\n",
       "Walk               -0.026335\n",
       "OtherTransp         0.007608\n",
       "WorkAtHome          0.441172\n",
       "MeanCommute         0.123553\n",
       "Employed            0.194114\n",
       "PrivateWork        -0.014917\n",
       "PublicWork         -0.071715\n",
       "SelfEmployed        0.164517\n",
       "FamilyWork          0.021470\n",
       "Unemployment       -0.432920\n",
       "Name: IncomePerCap, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr = df.corr()['IncomePerCap']\n",
    "corr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is the structure of your dataset?\n",
    "\n",
    "This dataset consists of 74,001 rows along with 37 columns. Those columns are 'TractId', 'State', 'County', 'TotalPop', 'Men', 'Women', 'Hispanic', 'White', 'Black', 'Native', 'Asian', 'Pacific', 'VotingAgeCitizen', 'Income', 'IncomeErr', 'IncomePerCap', 'IncomePerCapErr', 'Poverty', 'ChildPoverty', 'Professional', 'Service', 'Office', 'Construction', 'Production', 'Drive', 'Carpool', 'Transit', 'Walk', 'OtherTransp', 'WorkAtHome', 'MeanCommute', 'Employed', 'PrivateWork', 'PublicWork', 'SelfEmployed', 'FamilyWork', and 'Unemployment'.\n",
    "\n",
    "### What is/are the main feature(s) of interest in your dataset?\n",
    "\n",
    "I am interested in the attributes that contribute to income per capita.\n",
    "\n",
    "### What features in the dataset do you think will help support your investigation into your feature(s) of interest?\n",
    "\n",
    "Based on the coorelation chart above, the following attributes are strong enough to further examine: Poverty, ChildPoverty, Professional, Service, Construction, Production, WorkAtHome, and Unemployment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Univariate Exploration\n",
    "\n",
    "> In this section, investigate distributions of individual variables. If\n",
    "you see unusual points or outliers, take a deeper look to clean things up\n",
    "and prepare yourself to look at relationships between variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Make sure that, after every plot or related series of plots, that you\n",
    "include a Markdown cell with comments about what you observed, and what\n",
    "you plan on investigating next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discuss the distribution(s) of your variable(s) of interest. Were there any unusual points? Did you need to perform any transformations?\n",
    "\n",
    "> Your answer here!\n",
    "\n",
    "### Of the features you investigated, were there any unusual distributions? Did you perform any operations on the data to tidy, adjust, or change the form of the data? If so, why did you do this?\n",
    "\n",
    "> Your answer here!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bivariate Exploration\n",
    "\n",
    "> In this section, investigate relationships between pairs of variables in your\n",
    "data. Make sure the variables that you cover here have been introduced in some\n",
    "fashion in the previous section (univariate exploration)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Talk about some of the relationships you observed in this part of the investigation. How did the feature(s) of interest vary with other features in the dataset?\n",
    "\n",
    "> Your answer here!\n",
    "\n",
    "### Did you observe any interesting relationships between the other features (not the main feature(s) of interest)?\n",
    "\n",
    "> Your answer here!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multivariate Exploration\n",
    "\n",
    "> Create plots of three or more variables to investigate your data even\n",
    "further. Make sure that your investigations are justified, and follow from\n",
    "your work in the previous sections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Talk about some of the relationships you observed in this part of the investigation. Were there features that strengthened each other in terms of looking at your feature(s) of interest?\n",
    "\n",
    "> Your answer here!\n",
    "\n",
    "### Were there any interesting or surprising interactions between features?\n",
    "\n",
    "> Your answer here!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> At the end of your report, make sure that you export the notebook as an\n",
    "html file from the `File > Download as... > HTML` menu. Make sure you keep\n",
    "track of where the exported file goes, so you can put it in the same folder\n",
    "as this notebook for project submission. Also, make sure you remove all of\n",
    "the quote-formatted guide notes like this one before you finish your report!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
